import { Settings as CoreSettings } from "@llamaindex/core/global";
import { OpenAI } from "./llm/openai.js";
import { PromptHelper } from "./PromptHelper.js";
import { SentenceSplitter } from "@llamaindex/core/node-parser";
import { AsyncLocalStorage, getEnv } from "@llamaindex/env";
import { getEmbeddedModel, setEmbeddedModel, withEmbeddedModel } from "./internal/settings/EmbedModel.js";
/**
 * @internal
 */ class GlobalSettings {
    #prompt = {};
    #llm = null;
    #promptHelper = null;
    #nodeParser = null;
    #chunkOverlap;
    #llmAsyncLocalStorage = new AsyncLocalStorage();
    #promptHelperAsyncLocalStorage = new AsyncLocalStorage();
    #nodeParserAsyncLocalStorage = new AsyncLocalStorage();
    #chunkOverlapAsyncLocalStorage = new AsyncLocalStorage();
    #promptAsyncLocalStorage = new AsyncLocalStorage();
    get debug() {
        const debug = getEnv("DEBUG");
        return Boolean(debug) && debug?.includes("llamaindex") || debug === "*" || debug === "true";
    }
    get llm() {
        if (this.#llm === null) {
            this.#llm = new OpenAI();
        }
        return this.#llmAsyncLocalStorage.getStore() ?? this.#llm;
    }
    set llm(llm) {
        this.#llm = llm;
    }
    withLLM(llm, fn) {
        return this.#llmAsyncLocalStorage.run(llm, fn);
    }
    get promptHelper() {
        if (this.#promptHelper === null) {
            this.#promptHelper = new PromptHelper();
        }
        return this.#promptHelperAsyncLocalStorage.getStore() ?? this.#promptHelper;
    }
    set promptHelper(promptHelper) {
        this.#promptHelper = promptHelper;
    }
    withPromptHelper(promptHelper, fn) {
        return this.#promptHelperAsyncLocalStorage.run(promptHelper, fn);
    }
    get embedModel() {
        return getEmbeddedModel();
    }
    set embedModel(embedModel) {
        setEmbeddedModel(embedModel);
    }
    withEmbedModel(embedModel, fn) {
        return withEmbeddedModel(embedModel, fn);
    }
    get nodeParser() {
        if (this.#nodeParser === null) {
            this.#nodeParser = new SentenceSplitter({
                chunkSize: this.chunkSize,
                chunkOverlap: this.chunkOverlap
            });
        }
        return this.#nodeParserAsyncLocalStorage.getStore() ?? this.#nodeParser;
    }
    set nodeParser(nodeParser) {
        this.#nodeParser = nodeParser;
    }
    withNodeParser(nodeParser, fn) {
        return this.#nodeParserAsyncLocalStorage.run(nodeParser, fn);
    }
    get callbackManager() {
        return CoreSettings.callbackManager;
    }
    set callbackManager(callbackManager) {
        CoreSettings.callbackManager = callbackManager;
    }
    withCallbackManager(callbackManager, fn) {
        return CoreSettings.withCallbackManager(callbackManager, fn);
    }
    set chunkSize(chunkSize) {
        CoreSettings.chunkSize = chunkSize;
    }
    get chunkSize() {
        return CoreSettings.chunkSize;
    }
    withChunkSize(chunkSize, fn) {
        return CoreSettings.withChunkSize(chunkSize, fn);
    }
    get chunkOverlap() {
        return this.#chunkOverlapAsyncLocalStorage.getStore() ?? this.#chunkOverlap;
    }
    set chunkOverlap(chunkOverlap) {
        this.#chunkOverlap = chunkOverlap;
    }
    withChunkOverlap(chunkOverlap, fn) {
        return this.#chunkOverlapAsyncLocalStorage.run(chunkOverlap, fn);
    }
    get prompt() {
        return this.#promptAsyncLocalStorage.getStore() ?? this.#prompt;
    }
    set prompt(prompt) {
        this.#prompt = prompt;
    }
    withPrompt(prompt, fn) {
        return this.#promptAsyncLocalStorage.run(prompt, fn);
    }
}
export const llmFromSettingsOrContext = (serviceContext)=>{
    if (serviceContext?.llm) {
        return serviceContext.llm;
    }
    return Settings.llm;
};
export const nodeParserFromSettingsOrContext = (serviceContext)=>{
    if (serviceContext?.nodeParser) {
        return serviceContext.nodeParser;
    }
    return Settings.nodeParser;
};
export const embedModelFromSettingsOrContext = (serviceContext)=>{
    if (serviceContext?.embedModel) {
        return serviceContext.embedModel;
    }
    return Settings.embedModel;
};
export const promptHelperFromSettingsOrContext = (serviceContext)=>{
    if (serviceContext?.promptHelper) {
        return serviceContext.promptHelper;
    }
    return Settings.promptHelper;
};
export const Settings = new GlobalSettings();

import { SentenceSplitter } from "@llamaindex/core/node-parser";
import { PromptHelper } from "./PromptHelper.js";
import { OpenAIEmbedding } from "./embeddings/OpenAIEmbedding.js";
import { OpenAI } from "./llm/openai.js";
export function serviceContextFromDefaults(options) {
    const serviceContext = {
        llm: options?.llm ?? new OpenAI(),
        embedModel: options?.embedModel ?? new OpenAIEmbedding(),
        nodeParser: options?.nodeParser ?? new SentenceSplitter({
            chunkSize: options?.chunkSize,
            chunkOverlap: options?.chunkOverlap
        }),
        promptHelper: options?.promptHelper ?? new PromptHelper()
    };
    return serviceContext;
}
export function serviceContextFromServiceContext(serviceContext, options) {
    const newServiceContext = {
        ...serviceContext
    };
    if (options.llm) {
        newServiceContext.llm = options.llm;
    }
    if (options.promptHelper) {
        newServiceContext.promptHelper = options.promptHelper;
    }
    if (options.embedModel) {
        newServiceContext.embedModel = options.embedModel;
    }
    if (options.nodeParser) {
        newServiceContext.nodeParser = options.nodeParser;
    }
    return newServiceContext;
}
